{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Assignment3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9QcGnGPdX2C",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Install requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9O3aM3Tb28q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "06b672b5-665f-4048-ef76-bc9ba97235f4"
      },
      "source": [
        "!pip3 install 'torch==1.3.1'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.3.1\n",
            "  Using cached https://files.pythonhosted.org/packages/88/95/90e8c4c31cfc67248bf944ba42029295b77159982f532c5689bcfe4e9108/torch-1.3.1-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.3.1) (1.18.4)\n",
            "\u001b[31mERROR: torchvision 0.5.0 has requirement torch==1.4.0, but you'll have torch 1.3.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.4.0\n",
            "    Uninstalling torch-1.4.0:\n",
            "      Successfully uninstalled torch-1.4.0\n",
            "Successfully installed torch-1.3.1\n",
            "Requirement already satisfied: torchvision==0.5.0 in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.18.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.12.0)\n",
            "Collecting torch==1.4.0\n",
            "  Using cached https://files.pythonhosted.org/packages/24/19/4804aea17cd136f1705a5e98a00618cb8f6ccc375ad8bfa437408e09d058/torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.3.1\n",
            "    Uninstalling torch-1.3.1:\n",
            "      Successfully uninstalled torch-1.3.1\n",
            "Successfully installed torch-1.4.0\n",
            "Requirement already satisfied: Pillow-SIMD in /usr/local/lib/python3.6/dist-packages (7.0.0.post3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo942LMOdlh4",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DokFOdD1dJEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import alexnet\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torch.hub\n",
        "from torch.hub import load_state_dict_from_url\n",
        "from torch.autograd import Function\n",
        "import copy\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import ParameterGrid"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIDLJuIXK_vh",
        "colab_type": "text"
      },
      "source": [
        "**Set Arguments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5PkYfqfK_SA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE = 'cuda' # 'cuda' or 'cpu'\n",
        "\n",
        "NUM_CLASSES = 7\n",
        "\n",
        "BATCH_SIZE = 256     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "LR = 1e-3            # The initial Learning Rate\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
        "\n",
        "NUM_EPOCHS = 30      # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = 20       # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n",
        "\n",
        "\n",
        "ALPHA = 0.01"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gwii0TBHvzh",
        "colab_type": "text"
      },
      "source": [
        "**Define Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUDdw4j2H0Mc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define transforms\n",
        "transform = transforms.Compose([transforms.Resize(256),      # Resizes short size of the PIL image to 256\n",
        "                                      transforms.CenterCrop(224),  # Crops a central square patch of the image\n",
        "                                                                   # 224 because torchvision's AlexNet needs a 224x224 input!\n",
        "                                                                   # Remember this when applying different transformations, otherwise you get an error\n",
        "                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
        "                                      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)) # Normalizes tensor with mean and standard deviation\n",
        "])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qYIHPzYLY7i",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfVq_uDHLbsR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "97652abc-3a25-4968-b9b5-165cc26bf9fb"
      },
      "source": [
        "# Clone github repository with data\n",
        "if not os.path.isdir('./Homework3-PACS'):\n",
        "  !git clone https://github.com/MachineLearning2020/Homework3-PACS.git\n",
        "  \n",
        "DATA_DIR = 'Homework3-PACS/PACS'\n",
        "\n",
        "# Prepare Pytorch train/test Datasets\n",
        "# Photo\n",
        "source_dataset = torchvision.datasets.ImageFolder(DATA_DIR+'/photo', transform=transform)\n",
        "# Art\n",
        "target_dataset = torchvision.datasets.ImageFolder(DATA_DIR+'/art_painting', transform=transform)\n",
        "\n",
        "# Validation\n",
        "# Cartoon\n",
        "target_val_dataset1 = torchvision.datasets.ImageFolder(DATA_DIR+'/cartoon', transform=transform)\n",
        "# Sketch\n",
        "target_val_dataset2 = torchvision.datasets.ImageFolder(DATA_DIR+'/sketch', transform=transform)\n",
        "\n",
        "\n",
        "# Check dataset sizes\n",
        "print('Source Dataset - Photo: {}'.format(len(source_dataset)))\n",
        "print('Target Dataset - Art Painting: {}'.format(len(target_dataset)))\n",
        "\n",
        "print('Validation Dataset 1 - Cartoon: {}'.format(len(target_val_dataset1)))\n",
        "print('Validation Dataset 2 - Sketch: {}'.format(len(target_val_dataset2)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Source Dataset - Photo: 1670\n",
            "Target Dataset - Art Painting: 2048\n",
            "Validation Dataset 1 - Cartoon: 2344\n",
            "Validation Dataset 2 - Sketch: 3929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYEDQ7Z21ldN",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Dataloaders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VriRw8SI1nle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "source_dataloader = DataLoader(source_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "target_dataloader = DataLoader(target_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "target_val_dataloader1 = DataLoader(target_val_dataset1, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "target_val_dataloader2 = DataLoader(target_val_dataset2, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbZ1t5Qs2z4j",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GILBBXu1b26w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "__all__ = ['AlexNet', 'alexnet']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
        "}\n",
        "\n",
        "class ReverseLayerF(Function):\n",
        "    # Forwards identity\n",
        "    # Sends backward reversed gradients\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, alpha):\n",
        "        ctx.alpha = alpha\n",
        "\n",
        "        return x.view_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        output = grad_output.neg() * ctx.alpha\n",
        "\n",
        "        return output, None\n",
        "\n",
        "class DANN(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(DANN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.classifier = nn.Sequential( #Gy\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes), #1000 output neurons (ImageNet classes)\n",
        "        )\n",
        "\n",
        "        self.Gd = nn.Sequential( #Gd\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, 2), #2 output neurons\n",
        "        )\n",
        "\n",
        "    def forward(self, x, alpha=None):\n",
        "        \n",
        "        if alpha is not None:\n",
        "          x = self.features(x)\n",
        "          x = ReverseLayerF.apply(x, alpha)\n",
        "          x = self.avgpool(x)\n",
        "          x = torch.flatten(x, 1)\n",
        "          x = self.Gd(x)\n",
        "          return x # discriminator outputs\n",
        "        else:\n",
        "          x = self.features(x)\n",
        "          x = self.avgpool(x)\n",
        "          x = torch.flatten(x, 1)\n",
        "          x = self.classifier(x)\n",
        "          return x # class outputs\n",
        "\n",
        "\n",
        "def dann(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"AlexNet model architecture from the\n",
        "    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    model = DANN(**kwargs)\n",
        "\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls['alexnet'],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "        model.Gd[1].weight.data = copy.deepcopy(model.classifier[1].weight.data)\n",
        "        model.Gd[1].bias.data = copy.deepcopy(model.classifier[1].bias.data)\n",
        "        model.Gd[4].weight.data = copy.deepcopy(model.classifier[4].weight.data)\n",
        "        model.Gd[4].bias.data = copy.deepcopy(model.classifier[4].bias.data)\n",
        "\n",
        "    model.classifier[6] = nn.Linear(4096, 7)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEyL3H_R4qCf",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sjq00G94tSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = dann(pretrained=True, progress=False)\n",
        "\n",
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss() # for classification, we use Cross Entropy\n",
        "\n",
        "# Choose parameters to optimize\n",
        "# To access a different set of parameters, you have to access submodules of AlexNet\n",
        "# (nn.Module objects, like AlexNet, implement the Composite Pattern)\n",
        "# e.g.: parameters of the fully connected layers: net.classifier.parameters()\n",
        "# e.g.: parameters of the convolutional layers: look at alexnet's source code ;) \n",
        "parameters_to_optimize = net.parameters() # In this case we optimize over all the parameters of AlexNet\n",
        "\n",
        "# Define optimizer\n",
        "# An optimizer updates the weights based on loss\n",
        "# We use SGD with momentum\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "# Define scheduler\n",
        "# A scheduler dynamically changes learning rate\n",
        "# The most common schedule is the step(-down), which multiplies learning rate by gamma every STEP_SIZE epochs\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxYUli9d9uYQ",
        "colab_type": "text"
      },
      "source": [
        "**Train without adaptation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcoQ5fD49yT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# By default, everything is loaded to cpu\n",
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "\n",
        "cudnn.benchmark # Calling this optimizes runtime\n",
        "\n",
        "losses = []\n",
        "\n",
        "# Start iterating over the epochs\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  print('Starting epoch {}/{}, LR = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_lr()))\n",
        "\n",
        "  # Iterate over the dataset\n",
        "  for images, labels in source_dataloader:\n",
        "    # Bring data over the device of choice\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    net.train() # Sets module in training mode\n",
        "\n",
        "    # PyTorch, by default, accumulates gradients after each backward pass\n",
        "    # We need to manually set the gradients to zero before starting a new iteration\n",
        "    optimizer.zero_grad() # Zero-ing the gradients\n",
        "\n",
        "    # Forward pass to the network\n",
        "    outputs = net(images)\n",
        "\n",
        "    # Compute loss based on output and ground truth\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Compute gradients for each layer and update weights\n",
        "    loss.backward()  # backward pass: computes gradients\n",
        "    \n",
        "    \n",
        "    optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "\n",
        "  losses.append(loss.item())\n",
        "  \n",
        "  print(\"Loss: {}\".format(loss.item()))\n",
        "\n",
        "  # Step the scheduler\n",
        "  scheduler.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbjmR3boGIRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotWithoutAdaptation(losses, NUM_EPOCHS):\n",
        "  # Plot without adaptation\n",
        "  x = np.arange(1, NUM_EPOCHS+1)\n",
        "  plt.plot(x, losses, label=\"Training\")\n",
        "  plt.legend() #loc=\"upper right\"\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.title(\"Loss trend\")\n",
        "  plt.grid(axis=\"y\")\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e25aAoqxIgwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotWithoutAdaptation(losses, NUM_EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY4gGkOLJDPm",
        "colab_type": "text"
      },
      "source": [
        "**Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_IR3jODbHMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(net, DEVICE, target_dataloader, size_target_dataset):\n",
        "  net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "  net.train(False) # Set Network to evaluation mode\n",
        "\n",
        "  running_corrects = 0\n",
        "  for images, labels in tqdm(target_dataloader):\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    # Forward Pass\n",
        "    outputs = net(images)\n",
        "\n",
        "    # Get predictions\n",
        "    _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "    # Update Corrects\n",
        "    running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  accuracy = running_corrects / float(size_target_dataset)\n",
        "\n",
        "  print('Test Accuracy: {}'.format(accuracy))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCim77RWUAL8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "22977d06-9e6b-4a1b-fcd5-32a7787555bd"
      },
      "source": [
        "test(net, DEVICE, target_dataloader, len(target_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:07<00:00,  1.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.4921875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRPMDquDY8_r",
        "colab_type": "text"
      },
      "source": [
        "**Train with adaptation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QxBiAPNT1PO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "890507f0-bf35-4685-cff4-0731a2b41e2f"
      },
      "source": [
        "net = net.to(DEVICE)\n",
        "\n",
        "cudnn.benchmark\n",
        "\n",
        "loss_sc = [] # source class\n",
        "loss_sd = [] # source domain\n",
        "loss_td = [] # target domain\n",
        "\n",
        "# Start iterating over the epochs\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  print('Starting epoch {}/{}, LR = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_lr()))\n",
        "\n",
        "  # Iterate over the target dataset\n",
        "  for image, label in target_dataloader:\n",
        "    image = image.to(DEVICE)\n",
        "    label = label.to(DEVICE)\n",
        "  \n",
        "    images, labels = next(iter(source_dataloader)) # get a single batch of the source dataset (the smallest one)\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    net.train() \n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # STEP 1 \n",
        "    outputs = net(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward() \n",
        "    \n",
        "    # STEP 2\n",
        "    outputs2 = net(images, alpha=ALPHA)\n",
        "    labels2 = torch.zeros(len(labels)).long().to(DEVICE)\n",
        "    loss2 = criterion(outputs2, labels2)\n",
        "    loss2.backward()\n",
        "\n",
        "    # STEP 3\n",
        "    outputs3 = net(image, alpha=ALPHA)\n",
        "    labels3 = torch.ones(len(label)).long().to(DEVICE)\n",
        "    loss3 = criterion(outputs3, labels3)\n",
        "    loss3.backward()\n",
        "    \n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "  loss_sc.append(loss.item())\n",
        "  print(\"Source class loss: {}\".format(loss.item()))\n",
        "  loss_sd.append(loss2.item())\n",
        "  print(\"Source domain loss: {}\".format(loss2.item()))\n",
        "  loss_td.append(loss3.item())\n",
        "  print(\"Target domain loss: {}\".format(loss3.item()))\n",
        "\n",
        "  scheduler.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1/30, LR = [0.001]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:351: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Source class loss: 0.5728792548179626\n",
            "Source domain loss: 0.30617082118988037\n",
            "Target domain loss: 0.19320067763328552\n",
            "Starting epoch 2/30, LR = [0.001]\n",
            "Source class loss: 0.19653888046741486\n",
            "Source domain loss: 0.11650365591049194\n",
            "Target domain loss: 0.1325538009405136\n",
            "Starting epoch 3/30, LR = [0.001]\n",
            "Source class loss: 0.14657074213027954\n",
            "Source domain loss: 0.3090277910232544\n",
            "Target domain loss: 0.020938904955983162\n",
            "Starting epoch 4/30, LR = [0.001]\n",
            "Source class loss: 0.06652837991714478\n",
            "Source domain loss: 0.1716528832912445\n",
            "Target domain loss: 0.024447493255138397\n",
            "Starting epoch 5/30, LR = [0.001]\n",
            "Source class loss: 0.10354679822921753\n",
            "Source domain loss: 0.21504707634449005\n",
            "Target domain loss: 0.01771535724401474\n",
            "Starting epoch 6/30, LR = [0.001]\n",
            "Source class loss: 0.08558483421802521\n",
            "Source domain loss: 0.13177992403507233\n",
            "Target domain loss: 0.02538699470460415\n",
            "Starting epoch 7/30, LR = [0.001]\n",
            "Source class loss: 0.036608804017305374\n",
            "Source domain loss: 0.07393033057451248\n",
            "Target domain loss: 0.03389385715126991\n",
            "Starting epoch 8/30, LR = [0.001]\n",
            "Source class loss: 0.04863663762807846\n",
            "Source domain loss: 0.06809145212173462\n",
            "Target domain loss: 0.03189747408032417\n",
            "Starting epoch 9/30, LR = [0.001]\n",
            "Source class loss: 0.0378442108631134\n",
            "Source domain loss: 0.07259593904018402\n",
            "Target domain loss: 0.014731643721461296\n",
            "Starting epoch 10/30, LR = [0.001]\n",
            "Source class loss: 0.03764305263757706\n",
            "Source domain loss: 0.071904756128788\n",
            "Target domain loss: 0.0217449814081192\n",
            "Starting epoch 11/30, LR = [0.001]\n",
            "Source class loss: 0.0267624668776989\n",
            "Source domain loss: 0.13520202040672302\n",
            "Target domain loss: 0.017260685563087463\n",
            "Starting epoch 12/30, LR = [0.001]\n",
            "Source class loss: 0.02986576035618782\n",
            "Source domain loss: 0.07191116362810135\n",
            "Target domain loss: 0.029278870671987534\n",
            "Starting epoch 13/30, LR = [0.001]\n",
            "Source class loss: 0.03003910556435585\n",
            "Source domain loss: 0.06564632058143616\n",
            "Target domain loss: 0.01479097455739975\n",
            "Starting epoch 14/30, LR = [0.001]\n",
            "Source class loss: 0.028747189790010452\n",
            "Source domain loss: 0.05274321511387825\n",
            "Target domain loss: 0.018932409584522247\n",
            "Starting epoch 15/30, LR = [0.001]\n",
            "Source class loss: 0.024543441832065582\n",
            "Source domain loss: 0.06559108942747116\n",
            "Target domain loss: 0.017577368766069412\n",
            "Starting epoch 16/30, LR = [0.001]\n",
            "Source class loss: 0.01682974025607109\n",
            "Source domain loss: 0.04487931728363037\n",
            "Target domain loss: 0.013933085836470127\n",
            "Starting epoch 17/30, LR = [0.001]\n",
            "Source class loss: 0.015153677202761173\n",
            "Source domain loss: 0.0391480028629303\n",
            "Target domain loss: 0.022822583094239235\n",
            "Starting epoch 18/30, LR = [0.001]\n",
            "Source class loss: 0.011196641251444817\n",
            "Source domain loss: 0.05736443027853966\n",
            "Target domain loss: 0.012106707319617271\n",
            "Starting epoch 19/30, LR = [0.001]\n",
            "Source class loss: 0.011155668646097183\n",
            "Source domain loss: 0.04607919976115227\n",
            "Target domain loss: 0.015785416588187218\n",
            "Starting epoch 20/30, LR = [0.001]\n",
            "Source class loss: 0.02600007690489292\n",
            "Source domain loss: 0.02775530330836773\n",
            "Target domain loss: 0.018898461014032364\n",
            "Starting epoch 21/30, LR = [1e-05]\n",
            "Source class loss: 0.01692182384431362\n",
            "Source domain loss: 0.032454509288072586\n",
            "Target domain loss: 0.02611693926155567\n",
            "Starting epoch 22/30, LR = [0.0001]\n",
            "Source class loss: 0.008550679311156273\n",
            "Source domain loss: 0.04232838377356529\n",
            "Target domain loss: 0.010783430188894272\n",
            "Starting epoch 23/30, LR = [0.0001]\n",
            "Source class loss: 0.016242941841483116\n",
            "Source domain loss: 0.03407246246933937\n",
            "Target domain loss: 0.009074520319700241\n",
            "Starting epoch 24/30, LR = [0.0001]\n",
            "Source class loss: 0.011471277102828026\n",
            "Source domain loss: 0.03979520499706268\n",
            "Target domain loss: 0.014693373814225197\n",
            "Starting epoch 25/30, LR = [0.0001]\n",
            "Source class loss: 0.009157132357358932\n",
            "Source domain loss: 0.059453085064888\n",
            "Target domain loss: 0.015101735480129719\n",
            "Starting epoch 26/30, LR = [0.0001]\n",
            "Source class loss: 0.010559113696217537\n",
            "Source domain loss: 0.03703823313117027\n",
            "Target domain loss: 0.011815639212727547\n",
            "Starting epoch 27/30, LR = [0.0001]\n",
            "Source class loss: 0.008031431585550308\n",
            "Source domain loss: 0.02966710925102234\n",
            "Target domain loss: 0.014967934228479862\n",
            "Starting epoch 28/30, LR = [0.0001]\n",
            "Source class loss: 0.016425618901848793\n",
            "Source domain loss: 0.04482002556324005\n",
            "Target domain loss: 0.013608325272798538\n",
            "Starting epoch 29/30, LR = [0.0001]\n",
            "Source class loss: 0.007685501128435135\n",
            "Source domain loss: 0.02052382379770279\n",
            "Target domain loss: 0.016460977494716644\n",
            "Starting epoch 30/30, LR = [0.0001]\n",
            "Source class loss: 0.01460844837129116\n",
            "Source domain loss: 0.02980932593345642\n",
            "Target domain loss: 0.008945953100919724\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaLW12l4UuMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotWithAdaptation(loss_sc, loss_sd, loss_td, NUM_EPOCHS):\n",
        "  # Plot with adaptation\n",
        "  x = np.arange(1, NUM_EPOCHS+1)\n",
        "  plt.plot(x, loss_sc, label=\"Source class\")\n",
        "  plt.plot(x, loss_sd, label=\"Source domain\")\n",
        "  plt.plot(x, loss_td, label=\"Target domain\")\n",
        "  plt.legend() #loc=\"upper right\"\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.title(\"Loss trend\")\n",
        "  plt.grid(axis=\"y\")\n",
        "  plt.show()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkMotryXJBi0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "f757d1d2-49d8-44b8-e265-cf961801be37"
      },
      "source": [
        "plotWithAdaptation(loss_sc, loss_sd, loss_td, NUM_EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsHFI-GAJd69",
        "colab_type": "text"
      },
      "source": [
        "**Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO3HV5pqJg1o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "acafad29-73ab-47d4-8c50-ecc19b5fef45"
      },
      "source": [
        "test(net, DEVICE, target_dataloader, len(target_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:06<00:00,  1.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.5068359375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdYzB8R8L1l1",
        "colab_type": "text"
      },
      "source": [
        "**Cross Domain Validation without adaptation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy2MNAkhfwnQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "03209932-eecc-4876-9859-d6544ef11978"
      },
      "source": [
        "# VALIDARE ANCHE SUGLI ALTRI HYPERPARAMETRI E SALVARE L'ACCURACY PIù ALTA\n",
        "# DI OGNI COMBINAZIONE DI VALORI\n",
        "\n",
        "lr = [0.001, 0.01]\n",
        "num_epochs = [20, 30]\n",
        "step_size = [10, 20]\n",
        "\n",
        "params_grid = {\n",
        "    \"LearningRate\": lr,\n",
        "    \"Epochs\": num_epochs,\n",
        "    \"Step_size\": step_size\n",
        "}\n",
        "\n",
        "best_accuracy = 0.0\n",
        "best_lr = 0\n",
        "best_num_epochs = 0\n",
        "best_step_size = 0\n",
        "\n",
        "for p in ParameterGrid(params_grid):\n",
        "  LR = p[\"LearningRate\"]\n",
        "  NUM_EPOCHS = p[\"Epochs\"]\n",
        "  STEP_SIZE = p[\"Step_size\"]\n",
        "  print(f\"Learning rate: {LR}, Number of Epochs: {NUM_EPOCHS}, Step size: {STEP_SIZE}\")\n",
        "\n",
        "  net = dann(pretrained=True, progress=False)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  parameters_to_optimize = net.parameters()\n",
        "  optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "  scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
        "\n",
        "  losses_train = []\n",
        "  losses_valid = []\n",
        "  accuracies_train = []\n",
        "  accuracies_valid = []\n",
        "\n",
        "  net = net.to(DEVICE) \n",
        "  \n",
        "  cudnn.benchmark\n",
        "\n",
        "  for epoch in range(NUM_EPOCHS):\n",
        "    print('Starting epoch {}/{}, LR = {}, NUM_EPOCHS = {}, STEP_SIZE = {}'.format(epoch+1, NUM_EPOCHS, LR, NUM_EPOCHS, STEP_SIZE))\n",
        "    \n",
        "    # TRAINING\n",
        "    counterLosses_train = 0\n",
        "    running_corrects_train = 0\n",
        "    for images, labels in source_dataloader:\n",
        "      images = images.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "\n",
        "      net.train()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      outputs = net(images)\n",
        "\n",
        "      _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "      running_corrects_train += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "      loss = criterion(outputs, labels)\n",
        "      counterLosses_train += loss.item()*images.size(0)\n",
        "\n",
        "      loss.backward()\n",
        "    \n",
        "      optimizer.step()\n",
        "\n",
        "    loss_train = counterLosses_train/float(len(source_dataset))\n",
        "    losses_train.append(loss_train)\n",
        "    accuracy_train = running_corrects_train/float(len(source_dataset))\n",
        "    accuracies_train.append(accuracy_train)\n",
        "\n",
        "    #print(\"\\nTrain Loss: {} Train Accuracy: {}\".format(loss_train, accuracy_train)\n",
        "\n",
        "    # VALIDATION on cartoon\n",
        "    net.train(False)    \n",
        "\n",
        "    counterLosses_cartoon = 0\n",
        "    running_corrects_cartoon = 0\n",
        "    for images, labels in target_val_dataloader1:\n",
        "      images = images.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "      \n",
        "      outputs_cartoon = net(images)\n",
        "\n",
        "      _, preds = torch.max(outputs_cartoon.data, 1)\n",
        "\n",
        "      running_corrects_cartoon += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "      loss = criterion(outputs_cartoon, labels)\n",
        "\n",
        "      counterLosses_cartoon += loss.item()*images.size(0)\n",
        "    \n",
        "    accuracy_cartoon = running_corrects_cartoon/float(len(target_val_dataset1))\n",
        "    loss_cartoon = counterLosses_cartoon/float(len(target_val_dataset1))\n",
        "\n",
        "\n",
        "    # VALIDATION on sketch\n",
        "    counterLosses_sketch = 0\n",
        "    running_corrects_sketch = 0\n",
        "    for images, labels in target_val_dataloader2:\n",
        "      images = images.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "\n",
        "      outputs_sketch = net(images)\n",
        "\n",
        "      _, preds = torch.max(outputs_sketch.data, 1)\n",
        "\n",
        "      running_corrects_sketch += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "      loss = criterion(outputs_sketch, labels)\n",
        "\n",
        "      counterLosses_sketch += loss.item()*images.size(0)\n",
        "    \n",
        "    accuracy_sketch = running_corrects_sketch/float(len(target_val_dataset2))\n",
        "    loss_sketch = counterLosses_sketch/float(len(target_val_dataset2))\n",
        "\n",
        "    # we calculate the average accuracy of the two validation sets\n",
        "    val_accuracy = (accuracy_cartoon + accuracy_sketch)/2.0\n",
        "    val_loss = (loss_cartoon + loss_sketch)/2.0\n",
        "\n",
        "    accuracies_valid.append(val_accuracy)\n",
        "    accuracies_valid.append(val_loss)\n",
        "\n",
        "    #print(\"\\nValid Loss: {} Valid Accuracy: {}\".format(val_loss, val_accuracy)\n",
        "    print(\"\\nValid Accuracy: {}\".format(val_accuracy))\n",
        "    \n",
        "    # salva migliore val_accuracy per ogni learning rate\n",
        "\n",
        "    if val_accuracy > best_accuracy:\n",
        "      best_accuracy = val_accuracy\n",
        "      best_lr = LR\n",
        "      best_num_epochs = NUM_EPOCHS\n",
        "      best_step_size = STEP_SIZE\n",
        "    \n",
        "    # Step the scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "\n",
        "print(f\"\\nThe best validation accuracy is {best_accuracy} with learning rate = {best_lr}, number of epochs = {best_num_epochs} and step size = {best_step_size}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate: 0.001, Number of Epochs: 20, Step size: 10\n",
            "Starting epoch 1/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.23321366803422872\n",
            "Starting epoch 2/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2357515698876908\n",
            "Starting epoch 3/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.20170553997274143\n",
            "Starting epoch 4/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.18713619389209668\n",
            "Starting epoch 5/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.18104715135637078\n",
            "Starting epoch 6/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.1825366878996384\n",
            "Starting epoch 7/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.18858088580842375\n",
            "Starting epoch 8/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.19662365563843548\n",
            "Starting epoch 9/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.20410890794538206\n",
            "Starting epoch 10/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.21214076522089614\n",
            "Starting epoch 11/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.21273585233457004\n",
            "Starting epoch 12/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2117553511692612\n",
            "Starting epoch 13/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.21154204058905643\n",
            "Starting epoch 14/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.21120147116436194\n",
            "Starting epoch 15/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.21149719596211597\n",
            "Starting epoch 16/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2121783348115049\n",
            "Starting epoch 17/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.21239164539170968\n",
            "Starting epoch 18/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2131588359768137\n",
            "Starting epoch 19/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2131588359768137\n",
            "Starting epoch 20/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2131588359768137\n",
            "Learning rate: 0.001, Number of Epochs: 20, Step size: 20\n",
            "Starting epoch 1/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.3303728640710495\n",
            "Starting epoch 2/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.22819117839952674\n",
            "Starting epoch 3/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.20844542680357925\n",
            "Starting epoch 4/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.19795563878293637\n",
            "Starting epoch 5/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.19096850929945092\n",
            "Starting epoch 6/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.18526124329719412\n",
            "Starting epoch 7/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.18287361980616695\n",
            "Starting epoch 8/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.18661988347780614\n",
            "Starting epoch 9/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.1882366788655634\n",
            "Starting epoch 10/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.19491717099679723\n",
            "Starting epoch 11/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.20194187007089143\n",
            "Starting epoch 12/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.20602870316722507\n",
            "Starting epoch 13/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.20628685837437033\n",
            "Starting epoch 14/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.20708798103191722\n",
            "Starting epoch 15/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.21134328008151515\n",
            "Starting epoch 16/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.21355516258294627\n",
            "Starting epoch 17/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.2164409088974346\n",
            "Starting epoch 18/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.2165233231149838\n",
            "Starting epoch 19/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.21886610197907047\n",
            "Starting epoch 20/20, LR = 0.001, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.21802013469458312\n",
            "Learning rate: 0.01, Number of Epochs: 20, Step size: 10\n",
            "Starting epoch 1/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2175886273157418\n",
            "Starting epoch 2/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.194659015789652\n",
            "Starting epoch 3/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.30713292338322634\n",
            "Starting epoch 4/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.3087194242167066\n",
            "Starting epoch 5/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.3099386442980654\n",
            "Starting epoch 6/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2985847556934217\n",
            "Starting epoch 7/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.30502647461728966\n",
            "Starting epoch 8/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.3081316121393645\n",
            "Starting epoch 9/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2987095714286955\n",
            "Starting epoch 10/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.274091608560481\n",
            "Starting epoch 11/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.26978782736577667\n",
            "Starting epoch 12/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.26944725794108215\n",
            "Starting epoch 13/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.26722810040331935\n",
            "Starting epoch 14/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.26842191214883293\n",
            "Starting epoch 15/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2711573801008863\n",
            "Starting epoch 16/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2730771753227293\n",
            "Starting epoch 17/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2737619516902841\n",
            "Starting epoch 18/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.27461155649293734\n",
            "Starting epoch 19/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.27593262708294064\n",
            "Starting epoch 20/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.27669981766804463\n",
            "Learning rate: 0.01, Number of Epochs: 20, Step size: 20\n",
            "Starting epoch 1/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.19305677047455821\n",
            "Starting epoch 2/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.2521582426813135\n",
            "Starting epoch 3/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.2719997098672078\n",
            "Starting epoch 4/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.33166000258860995\n",
            "Starting epoch 5/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.30124264135504175\n",
            "Starting epoch 6/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.30950599680158997\n",
            "Starting epoch 7/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.3001942760448473\n",
            "Starting epoch 8/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.2772391476002804\n",
            "Starting epoch 9/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.26520650896414777\n",
            "Starting epoch 10/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.3049622479905698\n",
            "Starting epoch 11/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.30157593574340447\n",
            "Starting epoch 12/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.3140836776850531\n",
            "Starting epoch 13/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.3260739148034611\n",
            "Starting epoch 14/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.3198648884595773\n",
            "Starting epoch 15/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.2955765824615596\n",
            "Starting epoch 16/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.28509406947724847\n",
            "Starting epoch 17/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.27937952843866\n",
            "Starting epoch 18/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.27549145584986756\n",
            "Starting epoch 19/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.2642005451716778\n",
            "Starting epoch 20/20, LR = 0.01, NUM_EPOCHS = 20, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.26037186728248946\n",
            "Learning rate: 0.001, Number of Epochs: 30, Step size: 10\n",
            "Starting epoch 1/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.27475222529245646\n",
            "Starting epoch 2/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.27704646772012087\n",
            "Starting epoch 3/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.270487153805995\n",
            "Starting epoch 4/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.265435564025966\n",
            "Starting epoch 5/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2611463329039252\n",
            "Starting epoch 6/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.26166264331821576\n",
            "Starting epoch 7/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.26205169488801655\n",
            "Starting epoch 8/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2614978148831173\n",
            "Starting epoch 9/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2606445725622982\n",
            "Starting epoch 10/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.26771411626333286\n",
            "Starting epoch 11/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2683092033770067\n",
            "Starting epoch 12/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2686497728017012\n",
            "Starting epoch 13/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.26894913511762103\n",
            "Starting epoch 14/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.26894913511762103\n",
            "Starting epoch 15/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2689903422263957\n",
            "Starting epoch 16/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2685225139572115\n",
            "Starting epoch 17/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2687358245374163\n",
            "Starting epoch 18/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2692036528066004\n",
            "Starting epoch 19/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2692036528066004\n",
            "Starting epoch 20/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2689903422263957\n",
            "Starting epoch 21/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2689903422263957\n",
            "Starting epoch 22/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2689903422263957\n",
            "Starting epoch 23/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.26911760107088534\n",
            "Starting epoch 24/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2695442222312949\n",
            "Starting epoch 25/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2695442222312949\n",
            "Starting epoch 26/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2695442222312949\n",
            "Starting epoch 27/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2695442222312949\n",
            "Starting epoch 28/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2695442222312949\n",
            "Starting epoch 29/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2695442222312949\n",
            "Starting epoch 30/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2695442222312949\n",
            "Learning rate: 0.001, Number of Epochs: 30, Step size: 20\n",
            "Starting epoch 1/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.23430079734398196\n",
            "Starting epoch 2/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.24080799159483562\n",
            "Starting epoch 3/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.22195668942848185\n",
            "Starting epoch 4/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.20504456448375039\n",
            "Starting epoch 5/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.19355489329801936\n",
            "Starting epoch 6/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.18797852365841816\n",
            "Starting epoch 7/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.19552680818313461\n",
            "Starting epoch 8/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.20136133302988107\n",
            "Starting epoch 9/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.205055477038248\n",
            "Starting epoch 10/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.20615596201171477\n",
            "Starting epoch 11/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.20925865642457372\n",
            "Starting epoch 12/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.21648939104254095\n",
            "Starting epoch 13/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.22537085312070826\n",
            "Starting epoch 14/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.22970492886968955\n",
            "Starting epoch 15/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.23421474560826688\n",
            "Starting epoch 16/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.2354121948719463\n",
            "Starting epoch 17/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.23166229368214128\n",
            "Starting epoch 18/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.23217496657826592\n",
            "Starting epoch 19/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.23255674311173502\n",
            "Starting epoch 20/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.2322646558321469\n",
            "Starting epoch 21/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.2320513452519421\n",
            "Starting epoch 22/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.2324779664123517\n",
            "Starting epoch 23/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.23264643236561597\n",
            "Starting epoch 24/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.2335820889039843\n",
            "Starting epoch 25/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.2347310560225574\n",
            "Starting epoch 26/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.23413233139071765\n",
            "Starting epoch 27/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.2346862113956169\n",
            "Starting epoch 28/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.23540855735378047\n",
            "Starting epoch 29/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.23540855735378047\n",
            "Starting epoch 30/30, LR = 0.001, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.23532250561806536\n",
            "Learning rate: 0.01, Number of Epochs: 30, Step size: 10\n",
            "Starting epoch 1/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.27722823504578276\n",
            "Starting epoch 2/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2770524940561867\n",
            "Starting epoch 3/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.32820821501445885\n",
            "Starting epoch 4/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.3150714538866936\n",
            "Starting epoch 5/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2918267355630704\n",
            "Starting epoch 6/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.30774858690562956\n",
            "Starting epoch 7/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.3067063022228168\n",
            "Starting epoch 8/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.3081546316573097\n",
            "Starting epoch 9/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2463612874251757\n",
            "Starting epoch 10/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2626504195198563\n",
            "Starting epoch 11/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.26949574008618854\n",
            "Starting epoch 12/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.27563326476702077\n",
            "Starting epoch 13/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2824967729241824\n",
            "Starting epoch 14/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.28624667411398746\n",
            "Starting epoch 15/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.28633272584970254\n",
            "Starting epoch 16/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2859921564250081\n",
            "Starting epoch 17/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2855655352645985\n",
            "Starting epoch 18/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2850564998866397\n",
            "Starting epoch 19/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.28518012121296354\n",
            "Starting epoch 20/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.28534858716622785\n",
            "Starting epoch 21/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2852213283217382\n",
            "Starting epoch 22/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.28534858716622785\n",
            "Starting epoch 23/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2850080177415334\n",
            "Starting epoch 24/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2846674483168389\n",
            "Starting epoch 25/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2846674483168389\n",
            "Starting epoch 26/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2848807588970437\n",
            "Starting epoch 27/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2848807588970437\n",
            "Starting epoch 28/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.284753500052554\n",
            "Starting epoch 29/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2845401894723492\n",
            "Starting epoch 30/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 10\n",
            "\n",
            "Valid Accuracy: 0.2846674483168389\n",
            "Learning rate: 0.01, Number of Epochs: 30, Step size: 20\n",
            "Starting epoch 1/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.25422712185664137\n",
            "Starting epoch 2/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.26370486545743255\n",
            "Starting epoch 3/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.2879228642013487\n",
            "Starting epoch 4/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.2857994765448485\n",
            "Starting epoch 5/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.26236316416738403\n",
            "Starting epoch 6/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.30501073013567614\n",
            "Starting epoch 7/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.3005990720962616\n",
            "Starting epoch 8/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.30131050549992744\n",
            "Starting epoch 9/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.2997555479209901\n",
            "Starting epoch 10/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.2801988386870362\n",
            "Starting epoch 11/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.30435022198633244\n",
            "Starting epoch 12/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.3141479586030888\n",
            "Starting epoch 13/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.3189692446210336\n",
            "Starting epoch 14/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.3085921653722169\n",
            "Starting epoch 15/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.302357676401172\n",
            "Starting epoch 16/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.2967631191707414\n",
            "Starting epoch 17/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.3001688134176861\n",
            "Starting epoch 18/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.3066953896683191\n",
            "Starting epoch 19/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.31880197307671926\n",
            "Starting epoch 20/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.31786995405651686\n",
            "Starting epoch 21/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.3166797798291691\n",
            "Starting epoch 22/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.3134013444267141\n",
            "Starting epoch 23/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.3124208432614053\n",
            "Starting epoch 24/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.3112270315158917\n",
            "Starting epoch 25/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.30999201266160353\n",
            "Starting epoch 26/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.3092248220764995\n",
            "Starting epoch 27/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.3090115114962947\n",
            "Starting epoch 28/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.3084576314913955\n",
            "Starting epoch 29/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.3083715797556804\n",
            "Starting epoch 30/30, LR = 0.01, NUM_EPOCHS = 30, STEP_SIZE = 20\n",
            "\n",
            "Valid Accuracy: 0.30833037264690577\n",
            "\n",
            "The best validation accuracy is 0.33166000258860995 with learning rate = 0.01, number of epochs = 20 and step size = 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNuz_mQrMVZT",
        "colab_type": "text"
      },
      "source": [
        "**Train with best hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrmjybDZu1As",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "0ccefa44-8e53-4cfc-d49c-47658ce7c6fc"
      },
      "source": [
        "LR = best_lr\n",
        "NUM_EPOCHS = best_num_epochs\n",
        "STEP_SIZE = best_step_size\n",
        "\n",
        "net = dann(pretrained=True, progress=False)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "parameters_to_optimize = net.parameters()\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
        "\n",
        "net = net.to(DEVICE)\n",
        "\n",
        "cudnn.benchmark\n",
        "\n",
        "losses = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  print('Starting epoch {}/{}, LR = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_lr()))\n",
        "\n",
        "  for images, labels in source_dataloader:\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    net.train()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = net(images)\n",
        "\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    loss.backward()\n",
        "    \n",
        "    \n",
        "    optimizer.step()\n",
        "\n",
        "  losses.append(loss.item())\n",
        "  \n",
        "  print(\"Loss: {}\".format(loss.item()))\n",
        "\n",
        "  scheduler.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1/20, LR = [0.01]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:351: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.19738152623176575\n",
            "Starting epoch 2/20, LR = [0.01]\n",
            "Loss: 0.2841759920120239\n",
            "Starting epoch 3/20, LR = [0.01]\n",
            "Loss: 0.09191185981035233\n",
            "Starting epoch 4/20, LR = [0.01]\n",
            "Loss: 0.05950929597020149\n",
            "Starting epoch 5/20, LR = [0.01]\n",
            "Loss: 0.03632397577166557\n",
            "Starting epoch 6/20, LR = [0.01]\n",
            "Loss: 0.056191980838775635\n",
            "Starting epoch 7/20, LR = [0.01]\n",
            "Loss: 0.01473560743033886\n",
            "Starting epoch 8/20, LR = [0.01]\n",
            "Loss: 0.0022017229348421097\n",
            "Starting epoch 9/20, LR = [0.01]\n",
            "Loss: 0.006302798166871071\n",
            "Starting epoch 10/20, LR = [0.01]\n",
            "Loss: 0.020154161378741264\n",
            "Starting epoch 11/20, LR = [0.01]\n",
            "Loss: 0.004095315933227539\n",
            "Starting epoch 12/20, LR = [0.01]\n",
            "Loss: 0.0035316646099090576\n",
            "Starting epoch 13/20, LR = [0.01]\n",
            "Loss: 0.0014383234083652496\n",
            "Starting epoch 14/20, LR = [0.01]\n",
            "Loss: 0.0017032753676176071\n",
            "Starting epoch 15/20, LR = [0.01]\n",
            "Loss: 0.0012863371521234512\n",
            "Starting epoch 16/20, LR = [0.01]\n",
            "Loss: 0.001525677740573883\n",
            "Starting epoch 17/20, LR = [0.01]\n",
            "Loss: 0.004292704164981842\n",
            "Starting epoch 18/20, LR = [0.01]\n",
            "Loss: 0.0004034675657749176\n",
            "Starting epoch 19/20, LR = [0.01]\n",
            "Loss: 0.000870678573846817\n",
            "Starting epoch 20/20, LR = [0.01]\n",
            "Loss: 0.0003942437469959259\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c43xy4-ZeFK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "92f56caf-560b-4f1f-b980-5d0bda206a92"
      },
      "source": [
        "plotWithoutAdaptation(losses, NUM_EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLl6jiyzM5pt",
        "colab_type": "text"
      },
      "source": [
        "**Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxKd80PZ6JS1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5ca7f1b1-618e-4397-bb22-964a7882814d"
      },
      "source": [
        "test(net, DEVICE, target_dataloader, len(target_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:07<00:00,  1.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.509765625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7Vl5Zu-NBng",
        "colab_type": "text"
      },
      "source": [
        "**Cross Domain Validation with adaptation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSkMcMe0r1TL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b5df75df-0ebd-4796-90a9-2754dedd32c5"
      },
      "source": [
        "# CARTOON\n",
        "lr = [0.001, 0.01]\n",
        "alpha = [0.01, 0.03, 0.5]\n",
        "\n",
        "params_grid = {\n",
        "    \"LearningRate\": lr,\n",
        "    \"Alpha\": alpha\n",
        "}\n",
        "NUM_EPOCHS = 10\n",
        "accuracy_tot = []\n",
        "\n",
        "for p in ParameterGrid(params_grid):\n",
        "  LR = p[\"LearningRate\"]\n",
        "  ALPHA = p[\"Alpha\"]\n",
        "  print(f\"Learning rate: {LR}, Alpha: {ALPHA}\")\n",
        "\n",
        "  net = dann(pretrained=True, progress=False)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  parameters_to_optimize = net.parameters()\n",
        "  optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "  scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
        "\n",
        "  net = net.to(DEVICE) \n",
        "  cudnn.benchmark\n",
        "\n",
        "  for epoch in range(NUM_EPOCHS):\n",
        "    print('Starting epoch {}/{}, LR = {}, alpha = {}'.format(epoch+1, NUM_EPOCHS, LR, ALPHA))\n",
        "\n",
        "    for image, label in target_val_dataloader1: # passa target\n",
        "      image = image.to(DEVICE)\n",
        "      label = label.to(DEVICE)\n",
        "    \n",
        "      images, labels = next(iter(source_dataloader)) # get a single batch\n",
        "      images = images.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "\n",
        "      net.train()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # STEP 1\n",
        "      outputs = net(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "    \n",
        "      # STEP 2\n",
        "      outputs2 = net(images, alpha=ALPHA)\n",
        "      labels2 = torch.zeros(len(labels)).long().to(DEVICE)\n",
        "      loss2 = criterion(outputs2, labels2)\n",
        "      loss2.backward()\n",
        "\n",
        "      # STEP 3\n",
        "      outputs3 = net(image, alpha=ALPHA)\n",
        "      labels3 = torch.ones(len(label)).long().to(DEVICE)\n",
        "      loss3 = criterion(outputs3, labels3)\n",
        "      loss3.backward()\n",
        "    \n",
        "      optimizer.step()\n",
        "\n",
        "    # VALIDATION on cartoon\n",
        "    net.train(False)    \n",
        "\n",
        "    running_corrects = 0\n",
        "    for images, labels in target_val_dataloader1: # passa target\n",
        "      images = images.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "      \n",
        "      outputs = net(images)\n",
        "\n",
        "      _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "      running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "    \n",
        "    accuracy = running_corrects/float(len(target_val_dataset1)) # passa target\n",
        "\n",
        "    print(accuracy)\n",
        "\n",
        "    accuracy_tot.append(accuracy)\n",
        "\n",
        "\n",
        "    # Step the scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "#print(f\"\\nThe best validation accuracy is {best_accuracy} with learning rate = {best_lr} and alpha = {best_alpha}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate: 0.001, Alpha: 0.01\n",
            "Starting epoch 1/10, LR = 0.001, alpha = 0.01\n",
            "0.25554607508532423\n",
            "Starting epoch 2/10, LR = 0.001, alpha = 0.01\n",
            "0.24232081911262798\n",
            "Starting epoch 3/10, LR = 0.001, alpha = 0.01\n",
            "0.24829351535836178\n",
            "Starting epoch 4/10, LR = 0.001, alpha = 0.01\n",
            "0.25426621160409557\n",
            "Starting epoch 5/10, LR = 0.001, alpha = 0.01\n",
            "0.23976109215017063\n",
            "Starting epoch 6/10, LR = 0.001, alpha = 0.01\n",
            "0.23506825938566553\n",
            "Starting epoch 7/10, LR = 0.001, alpha = 0.01\n",
            "0.253839590443686\n",
            "Starting epoch 8/10, LR = 0.001, alpha = 0.01\n",
            "0.25\n",
            "Starting epoch 9/10, LR = 0.001, alpha = 0.01\n",
            "0.24786689419795221\n",
            "Starting epoch 10/10, LR = 0.001, alpha = 0.01\n",
            "0.25853242320819114\n",
            "Learning rate: 0.01, Alpha: 0.01\n",
            "Starting epoch 1/10, LR = 0.01, alpha = 0.01\n",
            "0.2815699658703072\n",
            "Starting epoch 2/10, LR = 0.01, alpha = 0.01\n",
            "0.2273890784982935\n",
            "Starting epoch 3/10, LR = 0.01, alpha = 0.01\n",
            "0.32081911262798635\n",
            "Starting epoch 4/10, LR = 0.01, alpha = 0.01\n",
            "0.2572525597269625\n",
            "Starting epoch 5/10, LR = 0.01, alpha = 0.01\n",
            "0.3024744027303754\n",
            "Starting epoch 6/10, LR = 0.01, alpha = 0.01\n",
            "0.34726962457337884\n",
            "Starting epoch 7/10, LR = 0.01, alpha = 0.01\n",
            "0.32295221843003413\n",
            "Starting epoch 8/10, LR = 0.01, alpha = 0.01\n",
            "0.27474402730375425\n",
            "Starting epoch 9/10, LR = 0.01, alpha = 0.01\n",
            "0.3212457337883959\n",
            "Starting epoch 10/10, LR = 0.01, alpha = 0.01\n",
            "0.29266211604095566\n",
            "Learning rate: 0.001, Alpha: 0.03\n",
            "Starting epoch 1/10, LR = 0.001, alpha = 0.03\n",
            "0.26493174061433444\n",
            "Starting epoch 2/10, LR = 0.001, alpha = 0.03\n",
            "0.21928327645051193\n",
            "Starting epoch 3/10, LR = 0.001, alpha = 0.03\n",
            "0.21203071672354948\n",
            "Starting epoch 4/10, LR = 0.001, alpha = 0.03\n",
            "0.2060580204778157\n",
            "Starting epoch 5/10, LR = 0.001, alpha = 0.03\n",
            "0.21416382252559726\n",
            "Starting epoch 6/10, LR = 0.001, alpha = 0.03\n",
            "0.22184300341296928\n",
            "Starting epoch 7/10, LR = 0.001, alpha = 0.03\n",
            "0.23037542662116042\n",
            "Starting epoch 8/10, LR = 0.001, alpha = 0.03\n",
            "0.22781569965870307\n",
            "Starting epoch 9/10, LR = 0.001, alpha = 0.03\n",
            "0.23506825938566553\n",
            "Starting epoch 10/10, LR = 0.001, alpha = 0.03\n",
            "0.24957337883959044\n",
            "Learning rate: 0.01, Alpha: 0.03\n",
            "Starting epoch 1/10, LR = 0.01, alpha = 0.03\n",
            "0.23464163822525597\n",
            "Starting epoch 2/10, LR = 0.01, alpha = 0.03\n",
            "0.26919795221843\n",
            "Starting epoch 3/10, LR = 0.01, alpha = 0.03\n",
            "0.33532423208191126\n",
            "Starting epoch 4/10, LR = 0.01, alpha = 0.03\n",
            "0.39121160409556316\n",
            "Starting epoch 5/10, LR = 0.01, alpha = 0.03\n",
            "0.4052901023890785\n",
            "Starting epoch 6/10, LR = 0.01, alpha = 0.03\n",
            "0.3387372013651877\n",
            "Starting epoch 7/10, LR = 0.01, alpha = 0.03\n",
            "0.37627986348122866\n",
            "Starting epoch 8/10, LR = 0.01, alpha = 0.03\n",
            "0.41424914675767915\n",
            "Starting epoch 9/10, LR = 0.01, alpha = 0.03\n",
            "0.43813993174061433\n",
            "Starting epoch 10/10, LR = 0.01, alpha = 0.03\n",
            "0.4180887372013652\n",
            "Learning rate: 0.001, Alpha: 0.5\n",
            "Starting epoch 1/10, LR = 0.001, alpha = 0.5\n",
            "0.2546928327645051\n",
            "Starting epoch 2/10, LR = 0.001, alpha = 0.5\n",
            "0.386518771331058\n",
            "Starting epoch 3/10, LR = 0.001, alpha = 0.5\n",
            "0.4014505119453925\n",
            "Starting epoch 4/10, LR = 0.001, alpha = 0.5\n",
            "0.3703071672354949\n",
            "Starting epoch 5/10, LR = 0.001, alpha = 0.5\n",
            "0.25170648464163825\n",
            "Starting epoch 6/10, LR = 0.001, alpha = 0.5\n",
            "0.1659556313993174\n",
            "Starting epoch 7/10, LR = 0.001, alpha = 0.5\n",
            "0.1659556313993174\n",
            "Starting epoch 8/10, LR = 0.001, alpha = 0.5\n",
            "0.1659556313993174\n",
            "Starting epoch 9/10, LR = 0.001, alpha = 0.5\n",
            "0.1659556313993174\n",
            "Starting epoch 10/10, LR = 0.001, alpha = 0.5\n",
            "0.1659556313993174\n",
            "Learning rate: 0.01, Alpha: 0.5\n",
            "Starting epoch 1/10, LR = 0.01, alpha = 0.5\n",
            "0.1659556313993174\n",
            "Starting epoch 2/10, LR = 0.01, alpha = 0.5\n",
            "0.1659556313993174\n",
            "Starting epoch 3/10, LR = 0.01, alpha = 0.5\n",
            "0.1659556313993174\n",
            "Starting epoch 4/10, LR = 0.01, alpha = 0.5\n",
            "0.1659556313993174\n",
            "Starting epoch 5/10, LR = 0.01, alpha = 0.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 262, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 186, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/shutil.py\", line 490, in rmtree\n",
            "    onerror(os.rmdir, path, sys.exc_info())\n",
            "  File \"/usr/lib/python3.6/shutil.py\", line 488, in rmtree\n",
            "    os.rmdir(path)\n",
            "OSError: [Errno 39] Directory not empty: '/tmp/pymp-83i5bvg0'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.1659556313993174\n",
            "Starting epoch 6/10, LR = 0.01, alpha = 0.5\n",
            "0.1659556313993174\n",
            "Starting epoch 7/10, LR = 0.01, alpha = 0.5\n",
            "0.1659556313993174\n",
            "Starting epoch 8/10, LR = 0.01, alpha = 0.5\n",
            "0.1659556313993174\n",
            "Starting epoch 9/10, LR = 0.01, alpha = 0.5\n",
            "0.1659556313993174\n",
            "Starting epoch 10/10, LR = 0.01, alpha = 0.5\n",
            "0.1659556313993174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9glynPU68UQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "116d9bcd-fdf4-4f10-ff43-90dc57fe6411"
      },
      "source": [
        "# SKETCH\n",
        "lr = [0.001, 0.01]\n",
        "alpha = [0.01, 0.03, 0.5]\n",
        "\n",
        "params_grid = {\n",
        "    \"LearningRate\": lr,\n",
        "    \"Alpha\": alpha\n",
        "}\n",
        "NUM_EPOCHS = 10\n",
        "accuracy_tot = []\n",
        "\n",
        "for p in ParameterGrid(params_grid):\n",
        "  LR = p[\"LearningRate\"]\n",
        "  ALPHA = p[\"Alpha\"]\n",
        "  print(f\"Learning rate: {LR}, Alpha: {ALPHA}\")\n",
        "\n",
        "  net = dann(pretrained=True, progress=False)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  parameters_to_optimize = net.parameters()\n",
        "  optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "  scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
        "\n",
        "  net = net.to(DEVICE) \n",
        "  cudnn.benchmark\n",
        "\n",
        "  for epoch in range(NUM_EPOCHS):\n",
        "    print('Starting epoch {}/{}, LR = {}, alpha = {}'.format(epoch+1, NUM_EPOCHS, LR, ALPHA))\n",
        "\n",
        "    for image, label in target_val_dataloader2: # passa target\n",
        "      image = image.to(DEVICE)\n",
        "      label = label.to(DEVICE)\n",
        "    \n",
        "      images, labels = next(iter(source_dataloader)) # get a single batch\n",
        "      images = images.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "\n",
        "      net.train()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # STEP 1\n",
        "      outputs = net(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "    \n",
        "      # STEP 2\n",
        "      outputs2 = net(images, alpha=ALPHA)\n",
        "      labels2 = torch.zeros(len(labels)).long().to(DEVICE)\n",
        "      loss2 = criterion(outputs2, labels2)\n",
        "      loss2.backward()\n",
        "\n",
        "      # STEP 3\n",
        "      outputs3 = net(image, alpha=ALPHA)\n",
        "      labels3 = torch.ones(len(label)).long().to(DEVICE)\n",
        "      loss3 = criterion(outputs3, labels3)\n",
        "      loss3.backward()\n",
        "    \n",
        "      optimizer.step()\n",
        "\n",
        "    # VALIDATION on sketch\n",
        "    net.train(False)    \n",
        "\n",
        "    running_corrects = 0\n",
        "    for images, labels in target_val_dataloader2: # passa target\n",
        "      images = images.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "      \n",
        "      outputs = net(images)\n",
        "\n",
        "      _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "      running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "    \n",
        "    accuracy = running_corrects/float(len(target_val_dataset2)) # passa target\n",
        "\n",
        "    print(accuracy)\n",
        "\n",
        "    accuracy_tot.append(accuracy)\n",
        "\n",
        "\n",
        "    # Step the scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "#print(f\"\\nThe best validation accuracy is {best_accuracy} with learning rate = {best_lr} and alpha = {best_alpha}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate: 0.001, Alpha: 0.01\n",
            "Starting epoch 1/10, LR = 0.001, alpha = 0.01\n",
            "0.17154492237210486\n",
            "Starting epoch 2/10, LR = 0.001, alpha = 0.01\n",
            "0.18019852379740392\n",
            "Starting epoch 3/10, LR = 0.001, alpha = 0.01\n",
            "0.17510817001781623\n",
            "Starting epoch 4/10, LR = 0.001, alpha = 0.01\n",
            "0.1901247136675999\n",
            "Starting epoch 5/10, LR = 0.001, alpha = 0.01\n",
            "0.19546958513616697\n",
            "Starting epoch 6/10, LR = 0.001, alpha = 0.01\n",
            "0.19037923135657928\n",
            "Starting epoch 7/10, LR = 0.001, alpha = 0.01\n",
            "0.19776024433698142\n",
            "Starting epoch 8/10, LR = 0.001, alpha = 0.01\n",
            "0.20412318656146602\n",
            "Starting epoch 9/10, LR = 0.001, alpha = 0.01\n",
            "0.19928735047085772\n",
            "Starting epoch 10/10, LR = 0.001, alpha = 0.01\n",
            "0.2043777042504454\n",
            "Learning rate: 0.01, Alpha: 0.01\n",
            "Starting epoch 1/10, LR = 0.01, alpha = 0.01\n",
            "0.31356579282260116\n",
            "Starting epoch 2/10, LR = 0.01, alpha = 0.01\n",
            "0.31102061593280733\n",
            "Starting epoch 3/10, LR = 0.01, alpha = 0.01\n",
            "0.3308729956731993\n",
            "Starting epoch 4/10, LR = 0.01, alpha = 0.01\n",
            "0.3405446678544159\n",
            "Starting epoch 5/10, LR = 0.01, alpha = 0.01\n",
            "0.3115296513107661\n",
            "Starting epoch 6/10, LR = 0.01, alpha = 0.01\n",
            "0.31509289895647746\n",
            "Starting epoch 7/10, LR = 0.01, alpha = 0.01\n",
            "0.3196742173581064\n",
            "Starting epoch 8/10, LR = 0.01, alpha = 0.01\n",
            "0.32374650038177655\n",
            "Starting epoch 9/10, LR = 0.01, alpha = 0.01\n",
            "0.32807330109442606\n",
            "Starting epoch 10/10, LR = 0.01, alpha = 0.01\n",
            "0.33672690251972515\n",
            "Learning rate: 0.001, Alpha: 0.03\n",
            "Starting epoch 1/10, LR = 0.001, alpha = 0.03\n",
            "0.175617205395775\n",
            "Starting epoch 2/10, LR = 0.001, alpha = 0.03\n",
            "0.185543395265971\n",
            "Starting epoch 3/10, LR = 0.001, alpha = 0.03\n",
            "0.17943497073046577\n",
            "Starting epoch 4/10, LR = 0.001, alpha = 0.03\n",
            "0.18630694833290914\n",
            "Starting epoch 5/10, LR = 0.001, alpha = 0.03\n",
            "0.19546958513616697\n",
            "Starting epoch 6/10, LR = 0.001, alpha = 0.03\n",
            "0.19063374904555866\n",
            "Starting epoch 7/10, LR = 0.001, alpha = 0.03\n",
            "0.19877831509289895\n",
            "Starting epoch 8/10, LR = 0.001, alpha = 0.03\n",
            "0.19394247900229067\n",
            "Starting epoch 9/10, LR = 0.001, alpha = 0.03\n",
            "0.20488673962840417\n",
            "Starting epoch 10/10, LR = 0.001, alpha = 0.03\n",
            "0.2031051158055485\n",
            "Learning rate: 0.01, Alpha: 0.03\n",
            "Starting epoch 1/10, LR = 0.01, alpha = 0.03\n",
            "0.2601170781369305\n",
            "Starting epoch 2/10, LR = 0.01, alpha = 0.03\n",
            "0.1677271570374141\n",
            "Starting epoch 3/10, LR = 0.01, alpha = 0.03\n",
            "0.27844235174344617\n",
            "Starting epoch 4/10, LR = 0.01, alpha = 0.03\n",
            "0.18427080682107405\n",
            "Starting epoch 5/10, LR = 0.01, alpha = 0.03\n",
            "0.21150419954186817\n",
            "Starting epoch 6/10, LR = 0.01, alpha = 0.03\n",
            "0.2031051158055485\n",
            "Starting epoch 7/10, LR = 0.01, alpha = 0.03\n",
            "0.1995418681598371\n",
            "Starting epoch 8/10, LR = 0.01, alpha = 0.03\n",
            "0.22295749554594044\n",
            "Starting epoch 9/10, LR = 0.01, alpha = 0.03\n",
            "0.24331891066429118\n",
            "Starting epoch 10/10, LR = 0.01, alpha = 0.03\n",
            "0.2443369814202087\n",
            "Learning rate: 0.001, Alpha: 0.5\n",
            "Starting epoch 1/10, LR = 0.001, alpha = 0.5\n",
            "0.1883430898447442\n",
            "Starting epoch 2/10, LR = 0.001, alpha = 0.5\n",
            "0.15474675489946552\n",
            "Starting epoch 3/10, LR = 0.001, alpha = 0.5\n",
            "0.1964876558920845\n",
            "Starting epoch 4/10, LR = 0.001, alpha = 0.5\n",
            "0.1964876558920845\n",
            "Starting epoch 5/10, LR = 0.001, alpha = 0.5\n",
            "0.1964876558920845\n",
            "Starting epoch 6/10, LR = 0.001, alpha = 0.5\n",
            "0.1964876558920845\n",
            "Starting epoch 7/10, LR = 0.001, alpha = 0.5\n",
            "0.1964876558920845\n",
            "Starting epoch 8/10, LR = 0.001, alpha = 0.5\n",
            "0.1964876558920845\n",
            "Starting epoch 9/10, LR = 0.001, alpha = 0.5\n",
            "0.1964876558920845\n",
            "Starting epoch 10/10, LR = 0.001, alpha = 0.5\n",
            "0.1964876558920845\n",
            "Learning rate: 0.01, Alpha: 0.5\n",
            "Starting epoch 1/10, LR = 0.01, alpha = 0.5\n",
            "0.1964876558920845\n",
            "Starting epoch 2/10, LR = 0.01, alpha = 0.5\n",
            "0.1964876558920845\n",
            "Starting epoch 3/10, LR = 0.01, alpha = 0.5\n",
            "0.1964876558920845\n",
            "Starting epoch 4/10, LR = 0.01, alpha = 0.5\n",
            "0.1964876558920845\n",
            "Starting epoch 5/10, LR = 0.01, alpha = 0.5\n",
            "0.1964876558920845\n",
            "Starting epoch 6/10, LR = 0.01, alpha = 0.5\n",
            "0.1964876558920845\n",
            "Starting epoch 7/10, LR = 0.01, alpha = 0.5\n",
            "0.1964876558920845\n",
            "Starting epoch 8/10, LR = 0.01, alpha = 0.5\n",
            "0.1964876558920845\n",
            "Starting epoch 9/10, LR = 0.01, alpha = 0.5\n",
            "0.1964876558920845\n",
            "Starting epoch 10/10, LR = 0.01, alpha = 0.5\n",
            "0.1964876558920845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFJH_uIFNkiI",
        "colab_type": "text"
      },
      "source": [
        "**Train with best hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOCpxLMbCaXN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "d14b9b3f-85b6-4a18-84c6-d70f837732b4"
      },
      "source": [
        "NUM_EPOCHS = 10\n",
        "LR = 0.01\n",
        "ALPHA = 0.03\n",
        "\n",
        "net = dann(pretrained=True, progress=False)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "parameters_to_optimize = net.parameters()\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
        "\n",
        "net = net.to(DEVICE)\n",
        "\n",
        "cudnn.benchmark\n",
        "\n",
        "loss_sc = [] # source class\n",
        "loss_sd = [] # source domain\n",
        "loss_td = [] # target domain\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  print('Starting epoch {}/{}, LR = {}, alpha = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_lr(), ALPHA))\n",
        "\n",
        "  # Iterate over the dataset\n",
        "  for image, label in target_dataloader:\n",
        "    image = image.to(DEVICE)\n",
        "    label = label.to(DEVICE)\n",
        "    \n",
        "    images, labels = next(iter(source_dataloader)) # get a single batch\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    net.train()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # STEP 1\n",
        "    outputs = net(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    \n",
        "    # STEP 2\n",
        "    outputs2 = net(images, alpha=ALPHA)\n",
        "    labels2 = torch.zeros(len(labels)).long().to(DEVICE)\n",
        "    loss2 = criterion(outputs2, labels2)\n",
        "    loss2.backward()\n",
        "\n",
        "    # STEP 3\n",
        "    outputs3 = net(image, alpha=ALPHA)\n",
        "    labels3 = torch.ones(len(label)).long().to(DEVICE)\n",
        "    loss3 = criterion(outputs3, labels3)\n",
        "    loss3.backward()\n",
        "    \n",
        "    optimizer.step()\n",
        "\n",
        "  loss_sc.append(loss.item())\n",
        "  print(\"Source class loss: {}\".format(loss.item()))\n",
        "  loss_sd.append(loss2.item())\n",
        "  print(\"Source domain loss: {}\".format(loss2.item()))\n",
        "  loss_td.append(loss3.item())\n",
        "  print(\"Target domain loss: {}\".format(loss3.item()))\n",
        "\n",
        "  scheduler.step()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1/10, LR = [0.01], alpha = 0.03\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:351: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Source class loss: 0.18946555256843567\n",
            "Source domain loss: 1.0289108753204346\n",
            "Target domain loss: 0.10294658690690994\n",
            "Starting epoch 2/10, LR = [0.01], alpha = 0.03\n",
            "Source class loss: 0.05911470949649811\n",
            "Source domain loss: 0.8530290722846985\n",
            "Target domain loss: 0.25897297263145447\n",
            "Starting epoch 3/10, LR = [0.01], alpha = 0.03\n",
            "Source class loss: 0.06926006823778152\n",
            "Source domain loss: 0.2459665834903717\n",
            "Target domain loss: 0.027493776753544807\n",
            "Starting epoch 4/10, LR = [0.01], alpha = 0.03\n",
            "Source class loss: 0.042487096041440964\n",
            "Source domain loss: 0.10286474972963333\n",
            "Target domain loss: 0.10004913806915283\n",
            "Starting epoch 5/10, LR = [0.01], alpha = 0.03\n",
            "Source class loss: 0.06547592580318451\n",
            "Source domain loss: 0.09324278682470322\n",
            "Target domain loss: 0.1574113667011261\n",
            "Starting epoch 6/10, LR = [0.01], alpha = 0.03\n",
            "Source class loss: 0.018816957250237465\n",
            "Source domain loss: 0.044851504266262054\n",
            "Target domain loss: 0.04150361567735672\n",
            "Starting epoch 7/10, LR = [0.01], alpha = 0.03\n",
            "Source class loss: 0.008532185107469559\n",
            "Source domain loss: 0.06367938220500946\n",
            "Target domain loss: 0.02130204066634178\n",
            "Starting epoch 8/10, LR = [0.01], alpha = 0.03\n",
            "Source class loss: 0.0009758379310369492\n",
            "Source domain loss: 0.05860685557126999\n",
            "Target domain loss: 0.03663402050733566\n",
            "Starting epoch 9/10, LR = [0.01], alpha = 0.03\n",
            "Source class loss: 0.0011344198137521744\n",
            "Source domain loss: 0.0907241553068161\n",
            "Target domain loss: 0.007047748658806086\n",
            "Starting epoch 10/10, LR = [0.01], alpha = 0.03\n",
            "Source class loss: 0.002751428633928299\n",
            "Source domain loss: 0.028062403202056885\n",
            "Target domain loss: 0.02150118350982666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj0lqLxhE8ht",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "0fb719e5-c540-4332-9daa-56b545c2852f"
      },
      "source": [
        "x = np.arange(1, NUM_EPOCHS+1)\n",
        "plt.plot(x, loss_sc, label=\"Source class\")\n",
        "plt.plot(x, loss_sd, label=\"Source domain\")\n",
        "plt.plot(x, loss_td, label=\"Target domain\")\n",
        "plt.legend() #loc=\"upper right\"\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss trend\")\n",
        "plt.grid(axis=\"y\")\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gI6z7jacN6zY",
        "colab_type": "text"
      },
      "source": [
        "**Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2W_lw9_FHC1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5bca344f-e791-4a37-84f8-cb3b479bdb05"
      },
      "source": [
        "test(net, \"cpu\", target_dataloader, len(target_dataset))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [01:06<00:00,  8.34s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.52880859375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}